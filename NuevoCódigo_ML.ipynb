{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sólo código necesario\n",
    "\n",
    "#Librerías y paquetes necesarios para el algoritmo.\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "#Carga de base de datos\n",
    "wdf = pd.read_csv('corrected_FINAL_DDBB.csv', header = \"infer\")\n",
    "\n",
    "#Eliminación de outliers, missing values y valores duplicados\n",
    "x1=list(wdf.loc[(wdf[\"label\"] == 1)][\"residue_conserv\"])\n",
    "l = []\n",
    "\n",
    "for i in x1:\n",
    "    l.append(i)\n",
    "    \n",
    "# Remove outliers and plot results\n",
    "new_l = sorted(l)[9:]\n",
    "\n",
    "# Se eliminan los outliers de los datos originales.\n",
    "wdf = wdf.drop(wdf.loc[(wdf[\"label\"] == 1) & (wdf[\"residue_conserv\"] <= 0.6197)].index)\n",
    "\n",
    "# Check for duplicates \n",
    "wdf[wdf[\"mutation\"].duplicated()]\n",
    "\n",
    "# Check for missing values\n",
    "wdf.isnull().sum()\n",
    "\n",
    "# Aquí no se cómo hacer para que los duplicados y los nulos no nos \n",
    "#salgan por pantalla\n",
    "\n",
    "#Se etiquetan los datos en 'benignos' y 'patógenos'\n",
    "y_be = (wdf.values[:,-1] == 0)\n",
    "y_pa = (wdf.values[:,-1] == 1)\n",
    "\n",
    "#Se dividen los datos en 'training set' y 'test set', y se realiza \n",
    "#un oversampling sobre los datos benignos de 'training set'\n",
    "\n",
    "X = wdf.values[:,2:-1]\n",
    "y = wdf.values[:,-1].astype('int')\n",
    "\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1012)\n",
    "\n",
    "# Create a df of X_train and y_train\n",
    "X_train_dfos = pd.DataFrame(X_train, columns = ['initial_aa', \n",
    "                                                'final_aa', \n",
    "                                                'topological_domain', \n",
    "                                                'functional_domain', \n",
    "                                                'd_size',\n",
    "                                                'd_hf',\n",
    "                                                'd_vol',\n",
    "                                                'd_msa',\n",
    "                                                'd_charge', \n",
    "                                                'd_pol', \n",
    "                                                'd_aro', \n",
    "                                                'residue_conserv',\n",
    "                                                'secondary_str',\n",
    "                                                'pLDDT',\n",
    "                                                'str_pos',\n",
    "                                                'MTR'])\n",
    "\n",
    "y_train_dfos = pd.DataFrame(y_train, columns = ['label'])\n",
    "\n",
    "##################### Oversampling ###########################\n",
    "# Concatenate our training data back together\n",
    "dfos = pd.concat([X_train_dfos, y_train_dfos], axis=1)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "# Separate majority and minority classes\n",
    "df_majority = dfos[dfos.label==1]\n",
    "df_minority = dfos[dfos.label==0]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority)//2,    \n",
    "                                 random_state=0)   # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Oversampled train datasets for machine learning models\n",
    "X_train_os = df_upsampled.values[:,:-1]\n",
    "y_train_os = df_upsampled.values[:,-1].astype(\"int\")\n",
    "\n",
    "#Se codifican los datos\n",
    "\n",
    "X_train_enc, X_test_enc, X_train_df, X_test_df = utils.categorical_encoding(X_train_os, X_test)\n",
    "X_train_df.columns \n",
    "\n",
    "#Se implementa el modelo 'ensemble' que es combinación de los\n",
    "#algoritmos LR1, SVC y RF\n",
    "\n",
    "X_train_fs, X_test_fs, featEn, posEn = utils.select_features(X_train_enc,\n",
    "                                                             X_train_df, \n",
    "                                                             y_train_os,\n",
    "                                                             X_test_enc, \n",
    "                                                             n = 45)\n",
    "\n",
    "\n",
    "\n",
    "pipeline_ensemble_soft = Pipeline( [(\"scaler\", StandardScaler()), \\\n",
    "                                        (\"Ensemble_soft\", VotingClassifier(voting = \"soft\",\n",
    "                                                                            weights = [1,0.5,1.75],\n",
    "                                                                            estimators=[\n",
    "                                         (\"logistic\", LogisticRegression(solver = \"saga\",\n",
    "                                                                                    penalty = \"l2\",\n",
    "                                                                                    max_iter = 10000,\n",
    "                                                                                    class_weight = {0: 3, 1: 2},\n",
    "                                                                                    multi_class = \"ovr\",\n",
    "                                                                                    C = 2.91,\n",
    "                                                                                    random_state = 8)),\n",
    "                                       (\"SVC\", SVC(kernel = \"linear\", \n",
    "                                                  class_weight= {0:1, 1:1},\n",
    "                                                                 probability=True,\n",
    "                                                                 decision_function_shape = \"ovr\",\n",
    "                                                                 degree = 2,\n",
    "                                                                 gamma = \"auto\", \n",
    "                                                                 C = 1,\n",
    "                                                                 random_state = 45)),\n",
    "                                        (\"RF\", RandomForestClassifier(max_depth = 3,\n",
    "                                                   criterion = \"log_loss\",\n",
    "                                                   max_features = \"log2\",\n",
    "                                                   oob_score = False,\n",
    "                                                   min_samples_split = 2, # min = 5\n",
    "                                                   class_weight= {0:3, 1:1},\n",
    "                                                   random_state = 45))]))])\n",
    "pipeline_ensemble_soft.fit(X_train_fs, y_train_os)\n",
    "\n",
    "\n",
    "#print(\"AUC-ROC VALUES:\")\n",
    "#print(utils.get_roc_auc_score(pipeline_ensemble_soft, X_train_fs, y_train_os, \n",
    "                                  #X_test_fs, y_test, print_table=True))\n",
    "\n",
    "#Se define un input para que el usuario introduzca la mutación que\n",
    "#se quiere analizar, se crea un dataframe porque tal y como está\n",
    "#escrito el código es lo más cómodo.\n",
    "\n",
    "mut = input(\"Enter your mutation:\")\n",
    "\n",
    "\n",
    "# Create a dataframe with it \n",
    "conflictive = pd.DataFrame(columns = [\"Mutationppt\"])\n",
    "c = pd.DataFrame({'Mutationppt':[mut]})\n",
    "challenge = pd.concat([conflictive, c])\n",
    "\n",
    "#Se generan los descriptores\n",
    "# Use utils KNCQ2_DDBB_generation function to create all descriptors\n",
    "ch_df = utils.KCNQ2_DDBB_generation(challenge)\n",
    "\n",
    "#Quitamos los posibles valores duplicados.\n",
    "#Ahora mismo esto no tiene mucho sentido ya que en el input sólo \n",
    "#podemos introducir las mutaciones de una en una, pero cuando \n",
    "#lo solucione será útil\n",
    "\n",
    "# Check for duplicates \n",
    "ch_df[ch_df[\"Mutationppt\"].duplicated()]\n",
    "\n",
    "# Remove duplicates if needed\n",
    "ch_df_clean = ch_df.drop_duplicates(subset = [\"Mutationppt\"])\n",
    "rest = ch_df.shape[0] -ch_df_clean.shape[0]\n",
    "\n",
    "# This variable contains all variants names\n",
    "variants_names = list(ch_df_clean[\"Mutationppt\"])\n",
    "\n",
    "#Se adapta la tabla a los requerimientos del algoritmo\n",
    "ch_df_clean = utils.preprocessing_ch(ch_df_clean)\n",
    "# Convert into numpy array\n",
    "X_ch = ch_df_clean.to_numpy()\n",
    "X_train_enc, X_ch_enc, X_train_df, X_ch_df = utils.categorical_encoding(X_train_os, X_ch)\n",
    "\n",
    "\n",
    "# Apply same feature selection as for ensemble algorithm\n",
    "X_train_fs, X_ch_enc_fs, feat_pred, pos_pred = utils.select_features(X_train_enc,\n",
    "                                                             X_train_df, \n",
    "                                                             y_train_os,\n",
    "                                                             X_ch_enc,\n",
    "                                                             n = 45)\n",
    "\n",
    "# Make prediction with MLb-KCNQ2 algorithm\n",
    "KCNQ2e_y_ch_p = pipeline_ensemble_soft.predict(X_ch_enc_fs)\n",
    "\n",
    "# View probabilities in prediction\n",
    "KCNQ2eprob = pipeline_ensemble_soft.predict_proba(X_ch_enc_fs)\n",
    "\n",
    "\n",
    "#Se saca por pantalla el resultado de la predicción\n",
    "if KCNQ2e_y_ch_p == 0:\n",
    "    proba0 = KCNQ2eprob[0,0]*100\n",
    "    print(\"Benign mutation\")\n",
    "    if proba0<=60:\n",
    "        print(\"Success rate: VERY LOW\")\n",
    "    elif 60 < proba0 <=70:\n",
    "        print(\"Success rate: LOW\")\n",
    "    elif 70 < proba0 <=80:\n",
    "        print(\"Success rate: MODERATE\")\n",
    "    elif 80 < proba0 <=90:\n",
    "        print(\"Success rate: HIGH\")\n",
    "    elif 90< proba0:\n",
    "        print(\"Success rate: VERY HIGH\")\n",
    "else:\n",
    "    proba1 = KCNQ2eprob[0,1]*100\n",
    "    print(\"Pathogenic mutation\")\n",
    "    if proba1<=60:\n",
    "        print(\"Success rate: VERY LOW\")\n",
    "    elif 60 < proba1 <=70:\n",
    "        print(\"Success rate: LOW\")\n",
    "    elif 70 < proba1 <=80:\n",
    "        print(\"Success rate: MODERATE\")\n",
    "    elif 80 < proba1 <=90:\n",
    "        print(\"Success rate: HIGH\")\n",
    "    elif 90< proba1:\n",
    "        print(\"Success rate: VERY HIGH\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d0319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
